{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd84195",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcfabc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91fe063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c35218c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fe093aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Naukari webpage on chrome automated browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f6ca77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the location and designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0db73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the location details\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e9674ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88f2569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a9fe6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_tags = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp = i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd873217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c63dddaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latentview</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...</td>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Varite</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jar</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_title  \\\n",
       "0                Latentview   \n",
       "1  Coresight Research, Inc.   \n",
       "2                    Varite   \n",
       "3         Artech infosystem   \n",
       "4                       Jar   \n",
       "5                 Cognizant   \n",
       "6                 Cognizant   \n",
       "7         Arrow Electronics   \n",
       "8         Arrow Electronics   \n",
       "9                 Accenture   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1  Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "               Company_name experience_required  \n",
       "0                Latentview             3-6 Yrs  \n",
       "1  Coresight Research, Inc.             4-8 Yrs  \n",
       "2                    Varite             2-5 Yrs  \n",
       "3         Artech infosystem             1-6 Yrs  \n",
       "4                       Jar             0-4 Yrs  \n",
       "5                 Cognizant             3-8 Yrs  \n",
       "6                 Cognizant             6-9 Yrs  \n",
       "7         Arrow Electronics            5-10 Yrs  \n",
       "8         Arrow Electronics             3-7 Yrs  \n",
       "9                 Accenture             6-8 Yrs  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frame from above data\"\n",
    "df = pd.DataFrame({\"job_title\":job_title,\"job_location\":job_location,\"Company_name\":company_name,\"experience_required\":experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc208eb",
   "metadata": {},
   "source": [
    "#Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "\n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manuall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3393ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Lbrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06950eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c24c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35d849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Naukari webpage on chrome automated browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ef80ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the location and designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ede12ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the location details\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3599959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92d7cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97c2b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_tags = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp = i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6480f204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fc642e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"job_title\":job_title,\"job_location\":job_location,\"Companhy_name\":company_name,\"experience_required\":experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80c4d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>Companhy_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        job_location            Companhy_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis   \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech   \n",
       "4  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates   \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra   \n",
       "6    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group   \n",
       "7                                Bangalore/Bengaluru                      IBM   \n",
       "8                                Bangalore/Bengaluru                  Walmart   \n",
       "9                 Bangalore/Bengaluru, Pune, Chennai                    Wipro   \n",
       "\n",
       "  experience_required  \n",
       "0             2-4 Yrs  \n",
       "1             4-7 Yrs  \n",
       "2            9-14 Yrs  \n",
       "3             5-9 Yrs  \n",
       "4             5-8 Yrs  \n",
       "5           10-14 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             4-8 Yrs  \n",
       "8             3-7 Yrs  \n",
       "9            8-13 Yrs  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b0263",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below\n",
    "    You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cda7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Library\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "042cdc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ea93ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0fe42c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Naukari webpage on chrome automated browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3cbedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the location and designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb0bc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the location details\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5584a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5812197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the salary check box\n",
    "loc=driver.find_element(By.XPATH,\"//span[@title='3-6 Lakhs']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83c2f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "exp_req = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "015acfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_tag  = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in job_title_tag[0:10]:\n",
    "    job = i.text\n",
    "    job_title.append(job)\n",
    "\n",
    "job_locations = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in job_locations[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "\n",
    "company_name_tag = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "for i in company_name_tag[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "experience_required = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience_required[0:10]:\n",
    "    exp = i.text\n",
    "    exp_req.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1526cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7b43d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"job_title\":job_title,\"job_location\":job_location,\"company_name\":company_name,\"exp_req\":exp_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20dea282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>exp_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Module Lead - BIDW</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geospatial Data Engineer/Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Louis Dreyfus Commodities</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scientific Computing (Proactive SO)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CGI</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                 Module Lead - BIDW   \n",
       "2                       Data Scientist/AIML Engineer   \n",
       "3                 Geospatial Data Engineer/Scientist   \n",
       "4  Python Programming Language Data Science Pract...   \n",
       "5                                     Data Scientist   \n",
       "6                Scientific Computing (Proactive SO)   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                    DigitalBCG GAMMA Data Scientist   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                 Noida, Nagpur, Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                     New Delhi, Bangalore/Bengaluru   \n",
       "\n",
       "                company_name   exp_req  \n",
       "0                  Accenture   2-4 Yrs  \n",
       "1                    Mphasis   5-8 Yrs  \n",
       "2                     upGrad   0-2 Yrs  \n",
       "3  Louis Dreyfus Commodities  5-10 Yrs  \n",
       "4                  Accenture   4-6 Yrs  \n",
       "5                GlobalLogic  8-10 Yrs  \n",
       "6                        CGI   3-7 Yrs  \n",
       "7                    Infosys   2-7 Yrs  \n",
       "8                    Infosys   2-7 Yrs  \n",
       "9    Boston Consulting Group   2-5 Yrs  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01268e87",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "631d57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6749e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")#connect to the driver\n",
    "driver.get('https://www.flipkart.com/')##Opening the Flipcart webpage on chrome automated browser\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04a9c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c7aa3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "eabc2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand= []\n",
    "description = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "124d9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')  #scraping brands name by xpath\n",
    "for i in brands:\n",
    "    brand.append(i.text)#appending the text in Brand list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0593b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=driver.find_elements(By.CLASS_NAME,'IRpwTa')#scraping description by class name\n",
    "for i in desc:\n",
    "    description.append(i.text)#appending the description in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d33e1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=driver.find_elements(By.CLASS_NAME,\"_30jeq3\")[:40]# scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a34f89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(brand), len(description), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "11d753fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "loc=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d7a33ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')  #scraping brands name by xpath\n",
    "for i in brands:\n",
    "    brand.append(i.text)#appending the text in Brand list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c2bb4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=driver.find_elements(By.CLASS_NAME,'IRpwTa')#scraping description by class name\n",
    "for i in desc:\n",
    "    description.append(i.text)#appending the description in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bdfc1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=driver.find_elements(By.CLASS_NAME,\"_30jeq3\")[:40]# scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b27aa920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(brand), len(description), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8a59c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the next button\n",
    "loc2=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "loc2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "25e69d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')  #scraping brands name by xpath\n",
    "for i in brands:\n",
    "    brand.append(i.text)#appending the text in Brand list\n",
    "    \n",
    "    \n",
    "desc=driver.find_elements(By.CLASS_NAME,'IRpwTa')#scraping description by class name\n",
    "for i in desc:\n",
    "    description.append(i.text)#appending the description in list\n",
    "    \n",
    "    \n",
    "prices=driver.find_elements(By.CLASS_NAME,\"_30jeq3\")[:40]# scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7fd3c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand), len(description), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dd6b946e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (54)</td>\n",
       "      <td>₹538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Aviator Sunglasses (60)</td>\n",
       "      <td>₹561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (68)</td>\n",
       "      <td>₹974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price\n",
       "0   ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...  ₹349\n",
       "1        ROYAL SON     UV Protection, Polarized Round Sunglasses (54)  ₹538\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799\n",
       "3          DEIXELS  Polarized, UV Protection, Riding Glasses Wayfa...  ₹249\n",
       "4            NuVew              UV Protection Aviator Sunglasses (57)  ₹198\n",
       "..             ...                                                ...   ...\n",
       "95       ROYAL SON   UV Protection, Polarized Aviator Sunglasses (60)  ₹561\n",
       "96        Fastrack        UV Protection Shield Sunglasses (Free Size)  ₹719\n",
       "97      PHENOMENAL  UV Protection, Mirrored Retro Square Sunglasse...  ₹369\n",
       "98   VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...  ₹799\n",
       "99       ROYAL SON    Polarized, UV Protection Sports Sunglasses (68)  ₹974\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],'Description':description[:100],'Price':price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e4d72",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "21be0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.flipkart.com/')\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bbaeb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding search bar with the help of Class name\n",
    "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, '_3704LK')))\n",
    "search_bar.send_keys('iphone 11')  # giving iphone11 as arguement in search bar \n",
    "search_bar.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "02864396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening iphone 11 from results\n",
    "phone = WebDriverWait(driver, 3).until(EC.presence_of_element_located((By.XPATH, '//a[@class=\"_1fQZEK\"]')))\n",
    "a = phone.get_attribute('href') # opening in same address, as flipkart opens new tab when clicked on link \n",
    "driver.get(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b094a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on all review to view all reviews for iphone 11\n",
    "all_review = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div')\n",
    "all_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "11bf7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "rating = []\n",
    "review_title = []\n",
    "review_description = []\n",
    "# appending page no. links in list to iterate over to get 100 results\n",
    "links = driver.find_elements(By.XPATH, '//a[@class=\"ge-49M\"]')\n",
    "link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c33815ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in links:\n",
    "    link.append(_.get_attribute('href'))\n",
    "# For first page, extracting review title\n",
    "review_title_element = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for _ in review_title_element:\n",
    "    a = _.text\n",
    "    review_title.append(a)\n",
    "# For first page, extracting review description\n",
    "review_description_element = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for _ in review_description_element:\n",
    "    a = _.text\n",
    "    review_description.append(a)\n",
    "# For first page, extracting review rating\n",
    "ratings_element = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for _ in ratings_element:\n",
    "    a = _.text\n",
    "    rating.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a17e8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in link:\n",
    "    \n",
    "    driver.get(i)  # opening extracted href, i.e. moving to next page\n",
    "    driver.implicitly_wait(5)  # wait for some time to allow page to load\n",
    "    \n",
    "        \n",
    "    review_title_element = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')  # Extracting review title and appending\n",
    "    for _ in review_title_element:\n",
    "        a = _.text\n",
    "        review_title.append(a)\n",
    "        \n",
    "    review_description_element = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')  # Extracting review description and appending\n",
    "    for _ in review_description_element:\n",
    "        a = _.text\n",
    "        review_description.append(a)\n",
    "        \n",
    "    ratings_element = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')  # Extracting review rating and appending\n",
    "    for _ in ratings_element:\n",
    "        a = _.text\n",
    "        rating.append(a)\n",
    "        \n",
    "        \n",
    "    links = driver.find_elements(By.XPATH, '//a[@class=\"ge-49M\"]')  # Finding additional page no. links in bottom nav bar \n",
    "    \n",
    "    # Appending new links, checking if not present\n",
    "    for _ in links:  \n",
    "        linka = _.get_attribute('href')\n",
    "        if linka not in link:\n",
    "            link.append(_.get_attribute('href'))\n",
    "            \n",
    "    if len(link) == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a9be9b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating         review_title  \\\n",
       "0      5       Simply awesome   \n",
       "1      4      Value-for-money   \n",
       "2      5     Perfect product!   \n",
       "3      5  Best in the market!   \n",
       "4      5    Worth every penny   \n",
       "5      5   Highly recommended   \n",
       "6      5     Perfect product!   \n",
       "7      5        Great product   \n",
       "8      5            Fabulous!   \n",
       "9      5    Worth every penny   \n",
       "\n",
       "                                  review_description  \n",
       "0  Really satisfied with the Product I received.....  \n",
       "1  I'm Really happy with the product\\nDelivery wa...  \n",
       "2  Amazing phone with great cameras and better ba...  \n",
       "3  Great iPhone very snappy experience as apple k...  \n",
       "4  Previously I was using one plus 3t it was a gr...  \n",
       "5  What a camera .....just awesome ..you can feel...  \n",
       "6  Value for money\\n5 star rating\\nExcellent came...  \n",
       "7  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "8  This is my first iOS phone. I am very happy wi...  \n",
       "9  i11 is worthy to buy, too much happy with the ...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame for saving/processing scrapped data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['rating'] = rating[:100]\n",
    "df['review_title'] = review_title[:100]\n",
    "df['review_description'] = review_description[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef066ef8",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ec08b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.flipkart.com/')\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "59e30244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching \"sneakers\" in web page\n",
    "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, '_3704LK')))\n",
    "search_bar.send_keys('sneakers')\n",
    "search_bar.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f2a6b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_names = []\n",
    "sneakers_names = []\n",
    "sneakers_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5b9e4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Page -------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')\n",
    "for i in brand_names_element[0:100]:  # finding brand_names and appending in brand names\n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "sneakers_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')\n",
    "for i in sneakers_names_element[0:100]:  # finding sneakers_names and appending in sneaker names\n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')\n",
    "for i in price_element[0:100]:  # finding price and appending in sneakers_price\n",
    "    text = i.text\n",
    "    sneakers_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6a58c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Page -------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')\n",
    "for i in brand_names_element[0:100]:  # finding brand_names and appending in brand Names\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "sneakers_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')\n",
    "for i in sneakers_names_element[0:100]:  # finding sneakers_names and appending in sneaker names\n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')\n",
    "for i in price_element[0:100]:  # finding price and appending in sneakers_price\n",
    "    text = i.text\n",
    "    sneakers_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "67aef31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neeman's</td>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Labbin</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>₹1,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kzaara</td>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹1,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>ARCADE 3.0 Sneakers For Men</td>\n",
       "      <td>₹636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>aadi</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹4,549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                     Product Description   Price\n",
       "0       Neeman's                                  BRUTON    ₹470\n",
       "1         BRUTON                                  Labbin    ₹499\n",
       "2   K- FOOTLANCE                                  BRUTON    ₹259\n",
       "3         Shozie                                RED TAPE  ₹1,499\n",
       "4         Kzaara                     World Wear Footwear    ₹298\n",
       "..           ...                                     ...     ...\n",
       "95        DUCATI  2 Combo Sneaker Shoes Sneakers For Men  ₹1,249\n",
       "96        BRUTON                        Sneakers For Men    ₹599\n",
       "97        BRUTON             ARCADE 3.0 Sneakers For Men    ₹636\n",
       "98          aadi  2 Combo Sneaker Shoes Sneakers For Men    ₹399\n",
       "99      Skechers                        Sneakers For Men  ₹4,549\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame for saving/processing scrapped data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand_names[:100]\n",
    "df['Product Description'] = sneakers_names[:100]\n",
    "df[\"Price\"] = sneakers_price[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0769523",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "eae3a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "28b8fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.ID, \"twotabsearchtextbox\")  # Finding element with the help ID\n",
    "product.send_keys('Laptop')  # Passing \"Laptop\" as an search keyword\n",
    "product.send_keys(Keys.RETURN)  # Pressing enter to load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ad628717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"i7 processor\" from Radio boxex and clicking it with the help of XPATH\n",
    "processor = driver.find_element(By.XPATH, '//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span')\n",
    "processor.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e073c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists, so we can append required data in specific list\n",
    "title = []\n",
    "rating = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fba54bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting laptop names\n",
    "laptop_name_element = driver.find_elements(By.XPATH, '//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for laptop in laptop_name_element[:10]:  # Looping for first 10 lapotps\n",
    "    i = laptop.text\n",
    "    title.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d8e6a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a ratings box\n",
    "ratings_box = driver.find_elements(By.XPATH, '//div[@class=\"a-row a-size-small\"]/span')\n",
    "for i in range(0, 20):  # With rating, we are extracting total ratings which is not required\n",
    "    ratings = ratings_box[i].get_attribute('aria-label')\n",
    "    # It works, so not touching it is good choice, in future update i will update, or i can pass pass, for future use\n",
    "    if len(ratings) > 10:\n",
    "        if len(rating) == 10:\n",
    "            break\n",
    "        else:\n",
    "            rating.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "70a31b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>1,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>93,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>1,11,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...  4.2 out of 5 stars   \n",
       "2  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...  4.3 out of 5 stars   \n",
       "3  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  4.2 out of 5 stars   \n",
       "4  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "5  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  4.5 out of 5 stars   \n",
       "6  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5 stars   \n",
       "8  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...  4.4 out of 5 stars   \n",
       "9  Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...  2.9 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    77,990  \n",
       "1  1,00,000  \n",
       "2    93,290  \n",
       "3    80,990  \n",
       "4    77,990  \n",
       "5    79,990  \n",
       "6    86,990  \n",
       "7    77,990  \n",
       "8  1,11,000  \n",
       "9    99,990  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding elements with price information and extracting prices\n",
    "price_element = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for _ in price_element[:10]:\n",
    "    i = _.text \n",
    "    price.append(i)  # Appending prices in lists\n",
    "# Creating data frame to extract/process scrapped information\n",
    "df = pd.DataFrame()\n",
    "df['Title'] = title\n",
    "df['Rating'] = rating\n",
    "df['Price'] = price\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7719442",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image.\n",
    "ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4efbb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "be0f0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding price element with the help of XPATH, and clicking check box \n",
    "price = driver.find_element(By.XPATH, '//*[@id=\"mountRoot\"]/div/div[1]/main/div/div[1]/section/div/div[5]/ul/li[2]')\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c9729452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding color element with the help of XPATH, and clicking check box for black color\n",
    "color = driver.find_element(By.XPATH, '//*[@id=\"mountRoot\"]/div/div[1]/main/div/div[1]/section/div/div[6]/ul/li[1]')\n",
    "color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ac85afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c4075801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brands=driver.find_elements(By.CLASS_NAME, 'product-brand') # scraping brands name by class name='product-brand'\n",
    "for i in brands:\n",
    "    brand.append(i.text)  # appending the company/brand in Brand list\n",
    "   \n",
    "desc = driver.find_elements(By.CLASS_NAME, 'product-product') # scraping description by class name = 'product-product'\n",
    "for i in desc:\n",
    "    description.append(i.text)  # appending the description in list\n",
    "\n",
    "prices=driver.find_elements(By.XPATH, '//div[@class=\"product-price\"]') # scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)  # appending the price in price list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e611c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to next page to access more web elements\n",
    "nxt_button=driver.find_element(By.XPATH, '//*[@id=\"desktopSearchResults\"]/div[2]/section/div[2]/ul/li[12]/a')#scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "305177fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brands=driver.find_elements(By.CLASS_NAME, 'product-brand')  # scraping brands name by class name='product-brand'\n",
    "for i in brands:\n",
    "    brand.append(i.text) # appending the company/brand in Brand list\n",
    "    \n",
    "desc=driver.find_elements(By.CLASS_NAME, 'product-product') # scraping description by class name = 'product-product'\n",
    "for i in desc:\n",
    "    description.append(i.text)  # appending the description in list\n",
    "\n",
    "prices=driver.find_elements(By.XPATH, '//div[@class=\"product-price\"]') # scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)  # appending the price in price list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cd715e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand\n",
    "df['Description'] = description\n",
    "df['Price | Actual Price | Discount'] = price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1cb1d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price | Actual Price | Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Response Super 3.0 Run</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR SonicSE Running Shoes</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men 4DFWD_Pulse Running Shoes</td>\n",
       "      <td>Rs. 8799Rs. 15999( 45 % OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men ENIGMA Running Shoes</td>\n",
       "      <td>Rs. 6649Rs. 9499(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men ChargedEscape 3 BL Running</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Textured Block Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>fitflop</td>\n",
       "      <td>Embellished PU Comfort Pumps</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>W omen TriBase Reign 4 Running</td>\n",
       "      <td>Rs. 8399Rs. 11999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men MAX ELITE Running Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                     Description  \\\n",
       "0         ADIDAS      Men Response Super 3.0 Run   \n",
       "1   UNDER ARMOUR  Men HOVR SonicSE Running Shoes   \n",
       "2         ADIDAS   Men 4DFWD_Pulse Running Shoes   \n",
       "3       Skechers        Men ENIGMA Running Shoes   \n",
       "4   UNDER ARMOUR  Men ChargedEscape 3 BL Running   \n",
       "..           ...                             ...   \n",
       "95          ALDO                    Men Sneakers   \n",
       "96          ALDO          Textured Block Sandals   \n",
       "97       fitflop    Embellished PU Comfort Pumps   \n",
       "98  UNDER ARMOUR  W omen TriBase Reign 4 Running   \n",
       "99      Skechers     Men MAX ELITE Running Shoes   \n",
       "\n",
       "   Price | Actual Price | Discount  \n",
       "0                         Rs. 8999  \n",
       "1        Rs. 8499Rs. 9999(15% OFF)  \n",
       "2     Rs. 8799Rs. 15999( 45 % OFF)  \n",
       "3        Rs. 6649Rs. 9499(30% OFF)  \n",
       "4        Rs. 7199Rs. 8999(20% OFF)  \n",
       "..                             ...  \n",
       "95                       Rs. 10999  \n",
       "96                        Rs. 7999  \n",
       "97                        Rs. 7499  \n",
       "98      Rs. 8399Rs. 11999(30% OFF)  \n",
       "99                        Rs. 8999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c9a33c",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d09aebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(r\"C:\\Users\\hp\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "# Accessing nav bar element with the help of XPATH, and clicking on it to access drop down list\n",
    "salary = driver.find_element(By.XPATH, '//*[@id=\"ambitionbox-header\"]/nav/ul/li[3]/span')\n",
    "salary.click()\n",
    "\n",
    "# Incase website takes more time load, giving time to load elements, to avoid no such element error \n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Accessing \"Browse salaries\" href, with the help of LINK TEXT name space\n",
    "second_click = driver.find_element(By.LINK_TEXT, 'Browse salaries')\n",
    "second_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8e92b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all elements with Relative XPATH\n",
    "elements = driver.find_elements(By.XPATH, '//div[@class=\"result-row\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6fea3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store companies information\n",
    "companies = []\n",
    "\n",
    "# looping through company names, and appending text to companies list\n",
    "for i in elements:\n",
    "    temp = i.find_elements(By.TAG_NAME, 'a')\n",
    "    for i in temp:\n",
    "        companies.append(i.text[:-22])  # Removing \"Data Scientist Salary\" from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e5f73893",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiance = []  # Creating empty list to store experiance required information\n",
    "\n",
    "# looping through elements, and appending experiance required to list\n",
    "for i in elements:\n",
    "    temp = i.find_elements(By.CLASS_NAME, 'sbold-list-header')\n",
    "    for i in temp:\n",
    "        experiance.append(i.text)\n",
    "        \n",
    "totaL_salary_record = []  # salary based on no. of feedbacks\n",
    "final_experiance = []  # Actual salary\n",
    "\n",
    "# looping through elements, and appending salary and total records processed\n",
    "for i in range(0, len(experiance)):\n",
    "    a = experiance[i].split(' (')\n",
    "    final_experiance.append(a[0])\n",
    "    totaL_salary_record.append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "39836aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding average salary\n",
    "avg_elements = driver.find_elements(By.XPATH, '//p[@class=\"averageCtc\"]')\n",
    "average_sal = []\n",
    "for i in avg_elements:\n",
    "    average_sal.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b43108b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_elements = driver.find_elements(By.XPATH, '//div[@class=\"salary-values\"]')\n",
    "min_max = []\n",
    "for i in min_max_elements:\n",
    "    min_max.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8142dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store salaries\n",
    "mina = []  # For storing minimum salary\n",
    "maxa = []  # For storing maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4f5e299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in min_max:\n",
    "    a = i.split('\\n')\n",
    "    # print(a)\n",
    "    mina.append(a[0])  # Appending minimum salary\n",
    "    maxa.append(a[1])  # Appending maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4fd298c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data frame to store/process information scrapped from website\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Creating columns\n",
    "df['Companies'] = companies\n",
    "df[\"Salary\"] = totaL_salary_record\n",
    "df[\"Experiance\"] = final_experiance\n",
    "df[\"Min Salary\"] = mina\n",
    "df[\"Avg Salary\"] = average_sal\n",
    "df[\"Max Salary\"] = maxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "189b3861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Experiance</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google\\nSo</td>\n",
       "      <td>based on 63 salaries)</td>\n",
       "      <td>1-4 yrs experience</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 34.9L</td>\n",
       "      <td>₹ 97.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation\\nSo</td>\n",
       "      <td>based on 344 salaries)</td>\n",
       "      <td>1-4 yrs experience</td>\n",
       "      <td>₹ 13.2L</td>\n",
       "      <td>₹ 23.9L</td>\n",
       "      <td>₹ 50.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs\\nSo</td>\n",
       "      <td>based on 37 salaries)</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 22.7L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arista Networks\\nSo</td>\n",
       "      <td>based on 52 salaries)</td>\n",
       "      <td>1-4 yrs experience</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 22.1L</td>\n",
       "      <td>₹ 38.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tekion\\nSo</td>\n",
       "      <td>based on 52 salaries)</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 21.9L</td>\n",
       "      <td>₹ 38.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon\\nSo</td>\n",
       "      <td>based on 147 salaries)</td>\n",
       "      <td>1-4 yrs experience</td>\n",
       "      <td>₹ 8.7L</td>\n",
       "      <td>₹ 21.2L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Servicenow Software Development India\\nSo</td>\n",
       "      <td>based on 82 salaries)</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "      <td>₹ 32.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walmart\\nSo</td>\n",
       "      <td>based on 112 salaries)</td>\n",
       "      <td>1-4 yrs experience</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 20.3L</td>\n",
       "      <td>₹ 32.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal\\nSo</td>\n",
       "      <td>based on 31 salaries)</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arcesium\\nSo</td>\n",
       "      <td>based on 71 salaries)</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 19.4L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Companies                  Salary  \\\n",
       "0                                 Google\\nSo   based on 63 salaries)   \n",
       "1                  Microsoft Corporation\\nSo  based on 344 salaries)   \n",
       "2                          Goldman Sachs\\nSo   based on 37 salaries)   \n",
       "3                        Arista Networks\\nSo   based on 52 salaries)   \n",
       "4                                 Tekion\\nSo   based on 52 salaries)   \n",
       "5                                 Amazon\\nSo  based on 147 salaries)   \n",
       "6  Servicenow Software Development India\\nSo   based on 82 salaries)   \n",
       "7                                Walmart\\nSo  based on 112 salaries)   \n",
       "8                                 PayPal\\nSo   based on 31 salaries)   \n",
       "9                               Arcesium\\nSo   based on 71 salaries)   \n",
       "\n",
       "           Experiance Min Salary Avg Salary Max Salary  \n",
       "0  1-4 yrs experience    ₹ 12.7L    ₹ 34.9L    ₹ 97.0L  \n",
       "1  1-4 yrs experience    ₹ 13.2L    ₹ 23.9L    ₹ 50.0L  \n",
       "2  1-2 yrs experience    ₹ 12.0L    ₹ 22.7L    ₹ 34.0L  \n",
       "3  1-4 yrs experience     ₹ 5.0L    ₹ 22.1L    ₹ 38.0L  \n",
       "4  2-4 yrs experience    ₹ 11.7L    ₹ 21.9L    ₹ 38.0L  \n",
       "5  1-4 yrs experience     ₹ 8.7L    ₹ 21.2L    ₹ 45.0L  \n",
       "6  2-4 yrs experience    ₹ 14.0L    ₹ 21.1L    ₹ 32.0L  \n",
       "7  1-4 yrs experience    ₹ 12.0L    ₹ 20.3L    ₹ 32.5L  \n",
       "8  1-2 yrs experience    ₹ 12.0L    ₹ 19.9L    ₹ 31.0L  \n",
       "9  1-2 yrs experience    ₹ 12.0L    ₹ 19.4L    ₹ 34.0L  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da540d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
